{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "narrative-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, roc_curve, log_loss, brier_score_loss, roc_auc_score, make_scorer\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function - Binned Sum of Squared Residuals\n",
    "\n",
    "def binned_sum_of_squared_residuals(y_actual, y_predicted):\n",
    "\n",
    "    df = pd.DataFrame(y_actual.copy())\n",
    "    df.columns = ['Actual']\n",
    "    df['Predicted Probability'] = y_predicted\n",
    "\n",
    "    bins = np.arange(0,1.05,0.05)\n",
    "    labels = ['0.05','0.1','0.15','0.2','0.25','0.3','0.35','0.4','0.45','0.5',\n",
    "              '0.55','0.6','0.65','0.7','0.75','0.8','0.85','0.9','0.95','1']\n",
    "    df['Bin'] = pd.cut(df['Predicted Probability'], bins = bins, labels = labels)\n",
    "    bin_df = df.groupby('Bin')['Actual', 'Predicted Probability'].mean()\n",
    "    bin_df.reset_index(inplace = True)\n",
    "    bin_df.columns = ['Bin', 'Actual', 'Predicted']\n",
    "\n",
    "    binned_sum_of_squares = sum(((bin_df.Actual - bin_df.Predicted).fillna(0)*100) ** 2)\n",
    "    \n",
    "    return binned_sum_of_squares\n",
    "\n",
    "# wrapper for grid search object\n",
    "bssr = make_scorer(binned_sum_of_squared_residuals, \n",
    "                   greater_is_better = False,\n",
    "                   needs_proba = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charming-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model, X_train, y_train):\n",
    "    \n",
    "    start_training = timer()\n",
    "\n",
    "    model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    end_training = timer()\n",
    "    print('Training Time:', round(end_training - start_training,1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seventh-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function\n",
    "\n",
    "def predict(model, X_validation):\n",
    "    \n",
    "    start_prediction = timer()\n",
    "\n",
    "    y_pred = pd.DataFrame(model.predict(X_validation), index = X_validation.index)\n",
    "    y_pred_prob = pd.DataFrame(model.predict_proba(X_validation)[:,1], index = X_validation.index)\n",
    "\n",
    "    end_prediction = timer()\n",
    "    print('Prediction Time:', round(end_prediction - start_prediction,1), 'seconds')\n",
    "    \n",
    "    return y_pred, y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Function\n",
    "\n",
    "def reports(model, X_columns, y_validation, y_pred, y_pred_prob):\n",
    "\n",
    "    start_reports = timer()\n",
    "\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_validation, y_pred))\n",
    "    print('Classification Report:\\n', classification_report(y_validation, y_pred))\n",
    "    print('Accuracy:', round((sum(y_pred.iloc[:,0] == y_validation.iloc[:,0]) / len(y_pred.values) * 100),2), \"%\")\n",
    "    print('Log Loss:', log_loss(y_validation, y_pred_prob))\n",
    "    print('Brier Score Loss:', brier_score_loss(y_validation, y_pred_prob))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_validation, y_pred_prob)\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n",
    "\n",
    "    print('ROC AUC Score:', roc_auc_score(y_validation, y_pred_prob))\n",
    "    \n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "    \n",
    "        forest_feature_importance = pd.DataFrame(zip(X_columns,model.feature_importances_))\n",
    "        forest_feature_importance.sort_values(1, inplace = True)\n",
    "        forest_feature_importance.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        plt.bar(forest_feature_importance[0][-20:],forest_feature_importance[1][-20:])\n",
    "        plt.xticks(rotation = 'vertical')\n",
    "        plt.title('20 Largest Importances')\n",
    "        plt.show()\n",
    "\n",
    "        plt.bar(forest_feature_importance[0][0:20],forest_feature_importance[1][0:20])\n",
    "        plt.xticks(rotation = 'vertical')\n",
    "        plt.title('20 Smallest Importances')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        feature_coef = pd.DataFrame(zip(X_columns,model.coef_[0]))\n",
    "        feature_coef.sort_values(1, inplace = True)\n",
    "        feature_coef.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        plt.bar(feature_coef[0][-20:],feature_coef[1][-20:])\n",
    "        plt.xticks(rotation = 'vertical')\n",
    "        plt.title('20 Largest Feature Coefficients')\n",
    "        plt.show()\n",
    "\n",
    "        plt.bar(feature_coef[0][0:20],feature_coef[1][0:20])\n",
    "        plt.xticks(rotation = 'vertical')\n",
    "        plt.title('20 Smallest Feature Coefficients')\n",
    "        plt.show()\n",
    "\n",
    "    proba_df = y_validation.copy()\n",
    "    proba_df['Predicted Probability'] = y_pred_prob\n",
    "\n",
    "    #The below bins by Predicted Probability\n",
    "    bins = np.arange(0,1.05,0.05)\n",
    "    labels = ['0.05','0.1','0.15','0.2','0.25','0.3','0.35','0.4','0.45','0.5',\n",
    "              '0.55','0.6','0.65','0.7','0.75','0.8','0.85','0.9','0.95','1']\n",
    "    proba_df['Bin'] = pd.cut(proba_df['Predicted Probability'], bins = bins, labels = labels)\n",
    "    #proba_df.reset_index(drop = True, inplace = True)\n",
    "    chart_df = proba_df.groupby('Bin')['Solved', 'Predicted Probability'].mean()\n",
    "    chart_df['Count'] = proba_df.groupby('Bin')['Solved'].count()\n",
    "    chart_df.reset_index(inplace = True)\n",
    "    chart_df.columns = ['Bin', 'Actual', 'Predicted', 'Count']\n",
    "\n",
    "    print(chart_df)\n",
    "\n",
    "    plt.bar(chart_df.Bin, chart_df.Count)\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.title('Frequency of Test Cases by Predicted Clearance Probability')\n",
    "    plt.xlabel('Case Clearance Probability')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(chart_df.Bin, chart_df.Actual, label = 'Actual', alpha = 1)\n",
    "    plt.scatter(chart_df.Bin, chart_df.Predicted, color = 'r', marker = 'D', label = 'Predicted', alpha = 0.75)\n",
    "    plt.legend()\n",
    "    plt.title('Actual and Predicted Clearance Rate by 5% Bin')\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.xlabel('Bin')\n",
    "    plt.yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "    plt.ylabel('Clearance Rate')\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(chart_df.Predicted, chart_df.Actual)\n",
    "    plt.plot([0,1],[0,1], linestyle = '--', color = 'g')\n",
    "    plt.title('Actual vs. Predicted Clearance Rate by 5% bin')\n",
    "    plt.xticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],rotation = 45)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(chart_df.Bin, chart_df.Actual - chart_df.Predicted,)\n",
    "    plt.title('Actual - Predicted Clearance Rate by 5% Bin')\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.xlabel('Bin (Range = Value - 5% to Value)')\n",
    "    #plt.yticks([-0.05,-0.04,-0.03,-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.05])\n",
    "    plt.ylabel('Delta Clearance Rate')\n",
    "    plt.show()\n",
    "\n",
    "    print('Sum of Squared Binned Residuals:', binned_sum_of_squared_residuals(y_validation, y_pred_prob))\n",
    "\n",
    "    end_reports = timer()\n",
    "    print('Reporting Time:', round(end_reports - start_reports,1), 'seconds')\n",
    "    \n",
    "    return proba_df, chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "green-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agentype', 'Solved', 'Year', 'Month', 'Homicide', 'Situation',\n",
       "       'VicAge', 'VicSex', 'VicRace', 'VicEthnic', 'Weapon', 'VicCount',\n",
       "       'AgencyCases', 'WhiteVictimPercent', 'AgeKnown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into DataFrame\n",
    "murders_df = pd.read_csv('C:\\\\Users\\\\Work_Remote\\\\Desktop\\\\murders_cleaned.csv')\n",
    "murders_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "practical-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1976\n",
       "1         1976\n",
       "2         1976\n",
       "3         1976\n",
       "4         1976\n",
       "          ... \n",
       "804713    2015\n",
       "804714    2017\n",
       "804715    2017\n",
       "804716    2018\n",
       "804717    2019\n",
       "Name: Year, Length: 804718, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "murders_df.Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "played-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-541794f82b9f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  murders_df.Solved[murders_df.Solved == 'Yes'] = 1\n",
      "<ipython-input-32-541794f82b9f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  murders_df.Solved[murders_df.Solved == 'No'] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time: 3.6 seconds\n"
     ]
    }
   ],
   "source": [
    "start_preprocessing = timer()\n",
    "\n",
    "# Encode y column\n",
    "murders_df.Solved[murders_df.Solved == 'Yes'] = 1\n",
    "murders_df.Solved[murders_df.Solved == 'No'] = 0\n",
    "\n",
    "# Divide categorical and numerical features\n",
    "X_categorical = murders_df[[\n",
    "                        'AgeKnown',\n",
    "                        'Agentype',\n",
    "                        'Month',\n",
    "                        'Homicide',\n",
    "                        'Situation',\n",
    "                        'VicSex',\n",
    "                        'VicRace',\n",
    "                        'VicEthnic',\n",
    "                        'Weapon'\n",
    "                            ]].reset_index(drop = True)\n",
    "\n",
    "X_numerical = murders_df[[\n",
    "                        'VicAge',\n",
    "                        'VicCount',\n",
    "                        'AgencyCases',\n",
    "                        'WhiteVictimPercent',\n",
    "                        'Year'\n",
    "                        ]].reset_index(drop = True)\n",
    "\n",
    "#Create y series\n",
    "y = pd.DataFrame(murders_df.Solved).reset_index(drop = True)\n",
    "\n",
    "#Create dummy columns for categorical features\n",
    "X = pd.get_dummies(X_categorical, drop_first = True)\n",
    "\n",
    "#Add numerical features to model dataframe\n",
    "X = pd.concat([X, X_numerical], axis = 1)\n",
    "\n",
    "#Scale features\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), index = X.index, columns = X.columns)\n",
    "\n",
    "#Create training set from all years except most recent\n",
    "X_train = X[murders_df.Year != 2019]\n",
    "y_train = y[murders_df.Year != 2019].astype('int')\n",
    "#Create most recent year test set\n",
    "X_test = X[murders_df.Year == 2019]\n",
    "y_test = y[murders_df.Year == 2019].astype('int')\n",
    "\n",
    "end_preprocessing = timer()\n",
    "print('Preprocessing Time:', round(end_preprocessing - start_preprocessing,1), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-gabriel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-friendship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-bradley",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corporate-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Solved\n",
       "1         426019\n",
       "0         177519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "graphic-output",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create balanced training set\n",
    "\n",
    "solved_count, unsolved_count = y_train.value_counts()\n",
    "solved = y_train[y_train.Solved == 1]\n",
    "unsolved = y_train[y_train.Solved == 0]\n",
    "solved_sample = solved.sample(unsolved_count, random_state = 33)\n",
    "\n",
    "y_train_balanced = pd.concat([unsolved, solved_sample], axis = 0)\n",
    "\n",
    "X_train_balanced = y_train_balanced.join(X_train,how = 'inner').drop('Solved', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-impression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-arthur",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = RandomForestClassifier(n_jobs = 9, \n",
    "                            random_state = 33,\n",
    "                            max_depth = 25,\n",
    "                            n_estimators = 1250,\n",
    "                            min_samples_leaf = 1)\n",
    "\n",
    "# Balanced? Wait for results\n",
    "\n",
    "train(model, X_train, y_train)\n",
    "y_pred, y_pred_prob = predict(model, X_test)\n",
    "proba_df, chart_df = reports(model, X_train.columns, y_test, y_pred, y_pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
